# Distributed Car Auction - Design Write-Up

## CAP Theorem Trade-offs

This system uses a **nuanced CAP approach**—different operations have different requirements:

| Operation | CAP Choice | Rationale |
|-----------|------------|-----------|
| **Bid Placement** | AP (Availability) | Accept all bids; don't lose customer engagement during partitions |
| **Winner Determination** | CP (Consistency) | Must be accurate; legal/financial implications |
| **Auction State** | CP (Consistency) | State transitions must be atomic and consistent |

### High-Availability Bidding

Bids are accepted **optimistically** without rejecting based on current highest bid:

```csharp
public void PlaceBid(Guid bidderId, decimal amount)
{
    // Accept all bids for availability
    Bid bid = new(bidderId, Id, amount, ++_bidSequence);
    _bids.Add(bid);
}
```

Users receive immediate feedback on whether their bid is currently the highest (`IsCurrentlyHighest`), but the bid is never rejected due to amount.

### Consistent Winner Resolution

Validity is enforced at **query time** when consistency matters:

```csharp
public List<Bid> GetValidBids()
{
    List<Bid> validBids = new();
    decimal currentHighest = StartingBid;
    
    foreach (Bid bid in _bids.OrderBy(b => b.Sequence))
    {
        if (bid.Amount > currentHighest)
        {
            validBids.Add(bid);
            currentHighest = bid.Amount;
        }
    }
    return validBids;
}
```

---

## Bid Consistency and Ordering

### The Challenge
In a distributed system, multiple bids may arrive simultaneously. We must ensure:
1. No bids are lost during network issues (availability)
2. Winner determination is accurate and auditable (consistency)

### Solution: Optimistic Acceptance + Sequence-Based Resolution

Each bid receives a monotonically increasing sequence number:

```csharp
Bid bid = new(bidderId, Id, amount, ++_bidSequence);
```

**Winner determination** filters to valid bids (each must exceed the previous):

```csharp
// Valid bids: those higher than previous in sequence order
foreach (Bid bid in _bids.OrderBy(b => b.Sequence))
{
    if (bid.Amount > currentHighest) { validBids.Add(bid); }
}
return validBids.LastOrDefault();  // Highest valid bid
```

### Scaling Considerations
For multi-instance deployments, the sequence would be generated by:
- Database auto-increment column, or
- Distributed sequence generator (e.g., Redis INCR), or
- Timestamp + node ID combination

---

## Broadcast Approach: Kafka-Based Event Streaming

### Architecture: Dual-Channel Communication

| Channel | Technology | Purpose |
|---------|------------|---------|
| **NotificationService** | SignalR/WebSockets | Real-time updates to connected users |
| **BroadcastService** | Apache Kafka | Reliable event streaming to partners |

### Why Kafka?

| Requirement | Kafka Solution |
|-------------|----------------|
| **Guaranteed Delivery** | Persistent log; messages retained until consumed |
| **Event Ordering** | Partition by `AuctionId` = ordered events per auction |
| **Partner Downtime** | Partners catch up from last offset when back online |
| **Audit Trail** | Full event history for replay and debugging |
| **Scalability** | Horizontal scaling with consumer groups |

### Kafka Topic Design

```
auction-events (partitioned by AuctionId)
├── AuctionCreated    { auctionId, title, timestamp }
├── AuctionStarted    { auctionId, timestamp }
├── AuctionEnded      { auctionId, winnerId, finalAmount, timestamp }
└── BidPlaced         { auctionId, lotId, bidderId, amount, sequence, timestamp }
```

### Event Flow

```
┌─────────────┐      Publish       ┌─────────────────────────────────────┐
│ Auction API │ ─────────────────► │           Kafka Cluster             │
└─────────────┘                    │  Topic: auction-events              │
                                   │  Partitions: by AuctionId           │
                                   └──────────────┬──────────────────────┘
                                                  │
                    ┌─────────────────────────────┼─────────────────────────────┐
                    │                             │                             │
                    ▼                             ▼                             ▼
         ┌──────────────────┐          ┌──────────────────┐          ┌──────────────────┐
         │ Partner A        │          │ Partner B        │          │ Webhook Adapter  │
         │ (Kafka Consumer) │          │ (Kafka Consumer) │          │ (for legacy)     │
         └──────────────────┘          └──────────────────┘          └──────────────────┘
```

### Event Schema

```csharp
public record AuctionEvent
{
    public Guid EventId { get; init; }           // Idempotency key
    public string EventType { get; init; }       // "BidPlaced", "AuctionEnded", etc.
    public Guid AuctionId { get; init; }         // Partition key
    public DateTime Timestamp { get; init; }
    public object Payload { get; init; }         // Event-specific data
}

public record BidPlacedPayload(
    Guid LotId,
    Guid BidderId,
    decimal Amount,
    long Sequence,
    bool IsCurrentlyHighest,
    decimal CurrentHighestBid
);
```

### Implementation

```csharp
public class KafkaBroadcastService : IBroadcastService
{
    private readonly IProducer<string, string> _producer;
    private const string TopicName = "auction-events";

    public async Task BroadcastBidAsync(Guid auctionId, Guid lotId, decimal amount)
    {
        AuctionEvent evt = new()
        {
            EventId = Guid.NewGuid(),
            EventType = "BidPlaced",
            AuctionId = auctionId,
            Timestamp = DateTime.UtcNow,
            Payload = new BidPlacedPayload(lotId, bidderId, amount, sequence, isHighest)
        };

        await _producer.ProduceAsync(TopicName, new Message<string, string>
        {
            Key = auctionId.ToString(),  // Partition key ensures ordering
            Value = JsonSerializer.Serialize(evt)
        });
    }
}
```

### Partner Integration Options

| Option | Use Case | Implementation |
|--------|----------|----------------|
| **Kafka Consumer** | Tech-savvy partners | Direct topic subscription |
| **Webhook Adapter** | Legacy partners | Kafka → HTTP POST adapter service |
| **REST Polling** | Simple integration | `/api/events?since={timestamp}` endpoint |

### Production Considerations

| Concern | Solution |
|---------|----------|
| **Idempotency** | `EventId` allows partners to deduplicate |
| **Schema Evolution** | Schema Registry (Avro/Protobuf) for compatibility |
| **Dead Letter Queue** | Failed webhook deliveries → DLQ for retry |
| **Monitoring** | Consumer lag alerts, throughput metrics |
| **Security** | SASL/SSL authentication, ACLs per partner |
| **Retention** | 7-day retention for replay capability |

---

*This Kafka-based design ensures reliable, ordered event delivery while supporting diverse partner integration patterns.*

